{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c468709d",
   "metadata": {},
   "source": [
    "# ImpPres Baseline\n",
    "\n",
    "This notebook illustrates how to use the DeBERTa-v3-base-mnli-fever-anli model to perform specialized inference on the ImpPres dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cec0d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fdf48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cfe31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "def evaluate(premise, hypothesis):\n",
    "    input = tokenizer(premise, hypothesis, truncation=True, return_tensors=\"pt\")\n",
    "    output = model(input[\"input_ids\"].to(device))\n",
    "    prediction = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
    "    prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(prediction, label_names)}\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2954d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entailment': 0.1, 'neutral': 99.8, 'contradiction': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"The weather is nice today.\", \"It is sunny outside.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923ea5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(pred_dict):\n",
    "    if pred_dict[\"entailment\"] > pred_dict[\"contradiction\"]  and pred_dict[\"entailment\"] > pred_dict[\"neutral\"]:\n",
    "        return \"entailment\"\n",
    "    elif pred_dict[\"contradiction\"] > pred_dict[\"entailment\"]:\n",
    "        return \"contradiction\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab422d",
   "metadata": {},
   "source": [
    "## Load ImpPres Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0438789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for section: presupposition_all_n_presupposition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset for section: presupposition_both_presupposition\n",
      "Loading dataset for section: presupposition_change_of_state\n",
      "Loading dataset for section: presupposition_cleft_existence\n",
      "Loading dataset for section: presupposition_cleft_uniqueness\n",
      "Loading dataset for section: presupposition_only_presupposition\n",
      "Loading dataset for section: presupposition_possessed_definites_existence\n",
      "Loading dataset for section: presupposition_possessed_definites_uniqueness\n",
      "Loading dataset for section: presupposition_question_presupposition\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sections = ['presupposition_all_n_presupposition', \n",
    "            'presupposition_both_presupposition', \n",
    "            'presupposition_change_of_state', \n",
    "            'presupposition_cleft_existence', \n",
    "            'presupposition_cleft_uniqueness', \n",
    "            'presupposition_only_presupposition', \n",
    "            'presupposition_possessed_definites_existence', \n",
    "            'presupposition_possessed_definites_uniqueness', \n",
    "            'presupposition_question_presupposition']\n",
    "\n",
    "dataset = {}\n",
    "for section in sections:\n",
    "    print(f\"Loading dataset for section: {section}\")\n",
    "    dataset[section] = load_dataset(\"facebook/imppres\", section)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e59927ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'presupposition_all_n_presupposition': DatasetDict({\n",
       "     all_n_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_both_presupposition': DatasetDict({\n",
       "     both_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_change_of_state': DatasetDict({\n",
       "     change_of_state: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_cleft_existence': DatasetDict({\n",
       "     cleft_existence: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_cleft_uniqueness': DatasetDict({\n",
       "     cleft_uniqueness: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_only_presupposition': DatasetDict({\n",
       "     only_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_possessed_definites_existence': DatasetDict({\n",
       "     possessed_definites_existence: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_possessed_definites_uniqueness': DatasetDict({\n",
       "     possessed_definites_uniqueness: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " }),\n",
       " 'presupposition_question_presupposition': DatasetDict({\n",
       "     question_presupposition: Dataset({\n",
       "         features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID'],\n",
       "         num_rows: 1900\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8262068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the ImpPres dataset\n",
    "from tqdm import tqdm\n",
    "def evaluate_on_dataset(dataset):\n",
    "    results = []\n",
    "    label_names = [\"entailment\", \"neutral\", \"contradiction\"]\n",
    "    for example in tqdm(dataset):\n",
    "        premise = example['premise']\n",
    "        hypothesis = example['hypothesis']\n",
    "        prediction = evaluate(premise, hypothesis)\n",
    "        results.append({\n",
    "            'premise': premise,\n",
    "            'hypothesis': hypothesis,\n",
    "            'prediction': prediction,\n",
    "            'pred_label': get_prediction(prediction),\n",
    "            'gold_label': label_names[example['gold_label']],\n",
    "            'section': example['section']\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e1258",
   "metadata": {},
   "source": [
    "## Evaluate Metrics\n",
    "\n",
    "Let's use the huggingface `evaluate` package to compute the performance of the baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e2e9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "f1 = load(\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ab24e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import combine\n",
    "\n",
    "clf_metrics = combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d04f0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666,\n",
       " 'f1': 0.6666666666666666,\n",
       " 'precision': 1.0,\n",
       " 'recall': 0.5}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_metrics.compute(predictions=[0, 1, 0], references=[0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909d58b",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Compute the classification metrics on the baseline model on each section of the ImpPres dataset.\n",
    "\n",
    "https://www.kaggle.com/code/faijanahamadkhan/llm-evaluation-framework-hugging-face provides good documentation on how to use the Huggingface evaluate library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a51fbc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'trigger', 'trigger1', 'trigger2', 'presupposition', 'gold_label', 'UID', 'pairID', 'paradigmID', 'section'],\n",
       "    num_rows: 17100\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "unified_pres = load_from_disk(\"unified_presupposition.hf\")\n",
    "unified_pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5405e9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17100/17100 [10:26<00:00, 27.30it/s]\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_on_dataset(unified_pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc04a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "from collections import defaultdict\n",
    "\n",
    "accuracy = load(\"accuracy\")\n",
    "macro_f1 = load(\"f1\")\n",
    "macro_precision = load(\"precision\")\n",
    "macro_recall = load(\"recall\")\n",
    "\n",
    "preds = defaultdict(list)\n",
    "refs = defaultdict(list)\n",
    "for res in results:\n",
    "    preds[res['section']].append(label_names.index(res['pred_label']))\n",
    "    refs[res['section']].append(label_names.index(res['gold_label']))\n",
    "\n",
    "\n",
    "classification_results = {}\n",
    "for section in preds:\n",
    "    classification_results[section] = (\n",
    "        accuracy.compute(predictions=preds[section], references=refs[section]) |\n",
    "        macro_f1.compute(predictions=preds[section], references=refs[section], average='macro') |\n",
    "        macro_precision.compute(predictions=preds[section], references=refs[section], average='macro') |\n",
    "        macro_recall.compute(predictions=preds[section], references=refs[section], average='macro')\n",
    "    )\n",
    "\n",
    "classification_results['total'] = (\n",
    "        accuracy.compute(predictions=[p for section in preds.values() for p in section], \n",
    "                        references=[r for section in refs.values() for r in section]) |\n",
    "        macro_f1.compute(predictions=[p for section in preds.values() for p in section], \n",
    "                        references=[r for section in refs.values() for r in section], average='macro') |\n",
    "        macro_precision.compute(predictions=[p for section in preds.values() for p in section], \n",
    "                                references=[r for section in refs.values() for r in section], average='macro') |\n",
    "        macro_recall.compute(predictions=[p for section in preds.values() for p in section], \n",
    "                            references=[r for section in refs.values() for r in section], average='macro')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4687294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Section",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Macro F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Macro Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Macro Recall",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1e444ab2-3068-42ad-a443-f1910aabbfe8",
       "rows": [
        [
         "0",
         "all_n_presupposition",
         "0.4626315789473684",
         "0.42030638562554695",
         "0.43341948311348716",
         "0.47500000000000003"
        ],
        [
         "1",
         "both_presupposition",
         "0.3968421052631579",
         "0.3158301906452839",
         "0.2751499289982959",
         "0.3936944444444445"
        ],
        [
         "2",
         "change_of_state",
         "0.30842105263157893",
         "0.3157356013981046",
         "0.33429174526941113",
         "0.3243611111111111"
        ],
        [
         "3",
         "cleft_existence",
         "0.6410526315789473",
         "0.6304930287013651",
         "0.6780821953208368",
         "0.6937777777777777"
        ],
        [
         "4",
         "cleft_uniqueness",
         "0.19526315789473683",
         "0.19109255682062387",
         "0.21449545547521856",
         "0.18586111111111112"
        ],
        [
         "5",
         "only_presupposition",
         "0.5831578947368421",
         "0.5649073441470372",
         "0.645943997728626",
         "0.6395833333333334"
        ],
        [
         "6",
         "possessed_definites_existence",
         "0.6705263157894736",
         "0.6635194448137137",
         "0.7986969947563872",
         "0.7367500000000001"
        ],
        [
         "7",
         "possessed_definites_uniqueness",
         "0.39",
         "0.2933117929218893",
         "0.25172491326197344",
         "0.3826388888888889"
        ],
        [
         "8",
         "question_presupposition",
         "0.6252631578947369",
         "0.5986525632475722",
         "0.6988201437460236",
         "0.6946666666666667"
        ],
        [
         "9",
         "total",
         "0.4747953216374269",
         "0.46791444528887555",
         "0.49322506515762726",
         "0.5029259259259259"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all_n_presupposition</td>\n",
       "      <td>0.462632</td>\n",
       "      <td>0.420306</td>\n",
       "      <td>0.433419</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>both_presupposition</td>\n",
       "      <td>0.396842</td>\n",
       "      <td>0.315830</td>\n",
       "      <td>0.275150</td>\n",
       "      <td>0.393694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>change_of_state</td>\n",
       "      <td>0.308421</td>\n",
       "      <td>0.315736</td>\n",
       "      <td>0.334292</td>\n",
       "      <td>0.324361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cleft_existence</td>\n",
       "      <td>0.641053</td>\n",
       "      <td>0.630493</td>\n",
       "      <td>0.678082</td>\n",
       "      <td>0.693778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleft_uniqueness</td>\n",
       "      <td>0.195263</td>\n",
       "      <td>0.191093</td>\n",
       "      <td>0.214495</td>\n",
       "      <td>0.185861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>only_presupposition</td>\n",
       "      <td>0.583158</td>\n",
       "      <td>0.564907</td>\n",
       "      <td>0.645944</td>\n",
       "      <td>0.639583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>possessed_definites_existence</td>\n",
       "      <td>0.670526</td>\n",
       "      <td>0.663519</td>\n",
       "      <td>0.798697</td>\n",
       "      <td>0.736750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>possessed_definites_uniqueness</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.293312</td>\n",
       "      <td>0.251725</td>\n",
       "      <td>0.382639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>question_presupposition</td>\n",
       "      <td>0.625263</td>\n",
       "      <td>0.598653</td>\n",
       "      <td>0.698820</td>\n",
       "      <td>0.694667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total</td>\n",
       "      <td>0.474795</td>\n",
       "      <td>0.467914</td>\n",
       "      <td>0.493225</td>\n",
       "      <td>0.502926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Section  Accuracy  Macro F1  Macro Precision  \\\n",
       "0            all_n_presupposition  0.462632  0.420306         0.433419   \n",
       "1             both_presupposition  0.396842  0.315830         0.275150   \n",
       "2                 change_of_state  0.308421  0.315736         0.334292   \n",
       "3                 cleft_existence  0.641053  0.630493         0.678082   \n",
       "4                cleft_uniqueness  0.195263  0.191093         0.214495   \n",
       "5             only_presupposition  0.583158  0.564907         0.645944   \n",
       "6   possessed_definites_existence  0.670526  0.663519         0.798697   \n",
       "7  possessed_definites_uniqueness  0.390000  0.293312         0.251725   \n",
       "8         question_presupposition  0.625263  0.598653         0.698820   \n",
       "9                           total  0.474795  0.467914         0.493225   \n",
       "\n",
       "   Macro Recall  \n",
       "0      0.475000  \n",
       "1      0.393694  \n",
       "2      0.324361  \n",
       "3      0.693778  \n",
       "4      0.185861  \n",
       "5      0.639583  \n",
       "6      0.736750  \n",
       "7      0.382639  \n",
       "8      0.694667  \n",
       "9      0.502926  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(classification_results).T\n",
    "df = df.rename(columns={\n",
    "    'accuracy': 'Accuracy',\n",
    "    'f1': 'Macro F1',\n",
    "    'precision': 'Macro Precision',\n",
    "    'recall': 'Macro Recall'\n",
    "})\n",
    "df.index.name = 'Section'\n",
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw2 (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
